import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
import statsmodels.api as sm
import kagglehub
import pandas as pd

from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
import pandas as pd
import folium
from folium.plugins import MarkerCluster
import pandas as pd
import folium
from folium.plugins import MarkerCluster
import plotly.express as px
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("./data/house/houseprice-with-lonlat.csv")
df = df[['Latitude', 'Longitude']].dropna()

# 2. ì§€ë„ ì¤‘ì‹¬
center_lat = df['Latitude'].mean()
center_lon = df['Longitude'].mean()
m = folium.Map(location=[center_lat, center_lon], zoom_start=12, width='100%', height='600px')

# 3. ë§ˆì»¤ ì¶”ê°€
marker_cluster = MarkerCluster().add_to(m)
for _, row in df.iterrows():
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=2,
        color='blue',
        fill=True,
        fill_opacity=0.6
    ).add_to(marker_cluster)

# âœ… 4. HTMLë¡œ ì €ì¥ (í´ë”ëŠ” qmd ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ)
# m.save("./data/house/house_gla.html")
m


# cond_qual_vars = [
#     'KitchenQual', 'FireplaceQu', 'BsmtCond', 'ExterCond', 'GarageCond',
#     'OverallCond', 'BsmtQual', 'ExterQual', 'GarageQual', 'HeatingQC' 'GrLivArea'
# ]
df['GrLivArea'].unique()

# ì§€ì—­ë³„ ìµœë¹ˆ ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
bsmt_cond_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['BsmtCondScore'] = df['BsmtCond'].map(bsmt_cond_mapping)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ìµœë¹ˆ ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['BsmtCondScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['BsmtCondScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
bsmt_color_map = {
    1: 'blue',       # Excellent
    2: 'green',      # Good
    3: 'gold',       # Typical
    4: 'orangered',  # Fair
    5: 'darkred'     # Poor
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='BsmtCondScore',
    category_orders={"BsmtCondScore": sorted(bsmt_color_map.keys())},
    color_discrete_map={str(k): v for k, v in bsmt_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜ (BsmtCondScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})


# ExterCond ì‹œê°í™”
# ì§€ì—­ë³„ ìµœë¹ˆ ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
bsmt_cond_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['ExterCondScore'] = df['ExterCond'].map(bsmt_cond_mapping)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ìµœë¹ˆ ì§€í•˜ì‹¤ ìƒíƒœ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['ExterCondScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['ExterCondScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
Exter_color_map = {
    1: 'blue',       # Excellent
    2: 'green',      # Good
    3: 'gold',       # Typical
    4: 'orangered',  # Fair
    5: 'darkred'     # Poor
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='ExterCondScore',
    category_orders={"ExterCondScore": sorted(Exter_color_map.keys())},
    color_discrete_map={str(k): v for k, v in Exter_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì™¸ì¥ì¬ ìƒíƒœ ì ìˆ˜ (ExterCondScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})


# GarageCond ì‹œê°í™”
# ì§€ì—­ë³„ ìµœë¹ˆ ì°¨ê³ ì§€ ìƒíƒœ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ì°¨ê³ ì§€ ìƒíƒœ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
Garage_cond_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['GarageCondScore'] = df['GarageCond'].map(bsmt_cond_mapping)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ìµœë¹ˆ ì°¨ê³ ì§€ ìƒíƒœ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['GarageCondScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['GarageCondScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
Garage_color_map = {
    1: 'blue',       # Excellent
    2: 'green',      # Good
    3: 'gold',       # Typical
    4: 'orangered',  # Fair
    5: 'darkred'     # Poor
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='GarageCondScore',
    category_orders={"GarageCondScore": sorted(Garage_color_map.keys())},
    color_discrete_map={str(k): v for k, v in Garage_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì°¨ê³ ì§€ ìƒíƒœ ì ìˆ˜ (GarageCondScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})


# Year_Remod_Add ì‹œê°í™”
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("./data/house/houseprice-with-lonlat.csv")

# 2. 10ë…„ ë‹¨ìœ„ë¡œ ë³€í™˜
df['RemodDecade'] = (df['YearRemodAdd'] // 10) * 10

# 3. ê²°ì¸¡ ì œê±°
df = df[['Latitude', 'Longitude', 'RemodDecade']].dropna()

# 4. Plotly ì‹œê°í™”
fig = px.scatter_mapbox(
    df,
    lat='Latitude',
    lon='Longitude',
    color='RemodDecade',
    color_continuous_scale='Plasma',  # ë˜ëŠ” Turbo, Viridis ë“±
    zoom=12,
    mapbox_style='carto-positron',
    title="ì „ì²´ ë¦¬ëª¨ë¸ë§ ì—°ë„ (10ë…„ ë‹¨ìœ„) ë¶„í¬"
)

fig.update_traces(marker=dict(size=6, opacity=0.7))
fig.show(config={"scrollZoom": True})


# ì§€ì—­ë³„ ì§€í•˜ì‹¤ í’ˆì§ˆ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ì§€í•˜ì‹¤ í’ˆì§ˆ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
BsmtQual_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['BsmtQualScore'] = df['BsmtQual'].map(bsmt_cond_mapping)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ì§€í•˜ì‹¤ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['BsmtQualScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['BsmtQualScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
bsmt_color_map = {
    1: 'blue',       # Excellent
    2: 'green',      # Good
    3: 'gold',       # Typical
    4: 'orangered',  # Fair
    5: 'darkred'     # Poor
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='BsmtQualScore',
    category_orders={"BsmtQualScore": sorted(bsmt_color_map.keys())},
    color_discrete_map={str(k): v for k, v in bsmt_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì§€í•˜ì‹¤ í’ˆì§ˆ ì ìˆ˜ (BsmtQualScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})



# ì§€ì—­ë³„ ì™¸ì¥ì¬ í’ˆì§ˆ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ì™¸ì¥ì¬ í’ˆì§ˆ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
ExterQual_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['ExterQualScore'] = df['ExterQual'].map(ExterQual_mapping)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ì™¸ì¥ì¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['ExterQualScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['ExterQualScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
Exter_color_map = {
    1: 'blue',       # Excellent
    2: 'green',      # Good
    3: 'gold',       # Typical
    4: 'orangered',  # Fair
    5: 'darkred'     # Poor
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='ExterQualScore',
    category_orders={"ExterQualScore": sorted(bsmt_color_map.keys())},
    color_discrete_map={str(k): v for k, v in bsmt_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì™¸ì¥ì¬ í’ˆì§ˆ ì ìˆ˜ (ExterQualScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})




# ì§€ì—­ë³„ ë‚œë°© í’ˆì§ˆ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ë‚œë°© í’ˆì§ˆ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
HeatingQC_mapping = {
    'Ex': 1,  # Excellent
    'Gd': 2,
    'TA': 3,
    'Fa': 4,
    'Po': 5   # Poor
}
df['HeatingQCScore'] = df['HeatingQC'].map(HeatingQC_mapping)
# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ì—­ë³„ ì™¸ì¥ì¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['HeatingQCScore'])
    .groupby(['Lat_bin', 'Lon_bin'])['HeatingQCScore']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)



# 6. ì‹œê°í™”
# ì ìˆ˜ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
mode_score['HeatingQCScore'] = mode_score['HeatingQCScore'].astype(str)

# ìƒ‰ìƒ ë§¤í•‘ (ì˜ë¯¸ ìˆëŠ” ìƒ‰ìƒ ì§ì ‘ ì§€ì •)
HeatingQC_color_map = {
    '1': 'darkred',     # ë§¤ìš° ë‚˜ì¨
    '2': 'orangered',   # ë‚˜ì¨
    '3': 'gold',        # ë³´í†µ
    '4': 'skyblue',     # ì¢‹ìŒ
    '5': 'darkblue'     # ë§¤ìš° ì¢‹ìŒ
}

# ì‹œê°í™”

fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='HeatingQCScore',
    category_orders={"HeatingQCScore": ['1', '2', '3', '4', '5']},
    color_discrete_map=HeatingQC_color_map,
    zoom=12,
    mapbox_style='carto-positron',
    title="ë‚œë°© í’ˆì§ˆ ì ìˆ˜ (HeatingQCScore)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.update_layout(dragmode='zoom')
fig.show(config={"scrollZoom": True})




# ì§€ìƒ ìƒí™œê³µê°„ ì ìˆ˜
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')
# 2. ì§€ìƒ ìƒí™œê³µê°„ ì ìˆ˜ ë§¤í•‘ (ë‚˜ì ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
df["GrLivArea_Score"] = pd.qcut(df["GrLivArea"], q=4, labels=[1, 2, 3, 4]).astype(int)

# 3. ìœ„ê²½ë„ êµ¬ê°„í™” (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼ â†’ ë°€ì§‘ë„ ê·¸ë£¹í™”)
df['Lat_bin'] = (df['Latitude'] * 1000).round() / 1000
df['Lon_bin'] = (df['Longitude'] * 1000).round() / 1000

# 4. ì§€ìƒ ìƒí™œê³µê°„ ì ìˆ˜ ê³„ì‚°
mode_score = (
    df.dropna(subset=['GrLivArea_Score'])
    .groupby(['Lat_bin', 'Lon_bin'])['GrLivArea_Score']
    .agg(lambda x: x.mode().iloc[0])
    .reset_index()
)

# 5. ìƒ‰ìƒ ë§¤í•‘ (ì ìˆ˜ ë†’ì„ìˆ˜ë¡ ë” ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
GrLivArea_color_map = {
    1: 'darkred',     # ë§¤ìš° ì¢ìŒ
    2: 'orangered',   # ì¢ìŒ
    3: 'gold',        # ë³´í†µ
    4: 'skyblue',     # ë„“ìŒ
    5: 'darkblue'    # ë§¤ìš° ë„“ìŒ
}

# 6. ì‹œê°í™”
fig = px.scatter_mapbox(
    mode_score,
    lat='Lat_bin',
    lon='Lon_bin',
    color='GrLivArea_Score',
    category_orders={"GrLivArea_Score": sorted(GrLivArea_color_map.keys())},
    color_discrete_map={str(k): v for k, v in GrLivArea_color_map.items()},
    zoom=12,
    mapbox_style='carto-positron',
    title= "ì§€ìƒ ìƒí™œ ê³µê°„ ì ìˆ˜ (GrLivArea_Score)"
)

fig.update_traces(marker=dict(size=10, opacity=0.8))
fig.show(config={"scrollZoom": True})

# # ìœ ì§€ ë³´ìˆ˜ ì ìˆ˜ ì‚°ì¶œ ë° ìƒìœ„ 25% ì¶œë ¥
# # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# df = pd.read_csv("./data/house/houseprice-with-lonlat.csv")

# # 2. ì‚¬ìš©í•  ë³€ìˆ˜
# cond_qual_vars = ['Bsmt_Cond', 'Exter_Cond', 'Garage_Cond', 'Heating_QC', 'Pool_QC', 'Overall_Cond', 'Year_Remod_Add']

# # 3. ë¬¸ìì—´ â†’ ì ìˆ˜ ë§¤í•‘
# qual_mapping = {
#     'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5,
#     'Poor': 1, 'Fair': 2, 'Typical': 3, 'Good': 4, 'Excellent': 5,
#     'No_Basement': 0, 'No_Pool': 0, 'No_Garage': 0,
#     'Average': 3, 'Below_Average': 2, 'Above_Average': 4, 'Very_Good': 5, 'Very_Poor': 1
# }

# df_model = df[cond_qual_vars].copy()
# for col in cond_qual_vars:
#     if df_model[col].dtype == object:
#         df_model[col] = df_model[col].map(qual_mapping)

# # 4. ë…¸í›„ë„ íŒŒìƒ ë³€ìˆ˜
# df_model['Age'] = 2024 - df_model['Year_Remod_Add']
# df_model.drop(columns='Year_Remod_Add', inplace=True)

# # 5. ê²°ì¸¡ì¹˜ 0ìœ¼ë¡œ ëŒ€ì²´
# df_model.fillna(0, inplace=True)

# # 6. íšŒê·€ í•™ìŠµì„ ìœ„í•œ ì„ì‹œ ì ìˆ˜ ìƒì„±
# initial_score = (
#     df_model['Age'] * 0.3 +
#     (6 - df_model['Overall_Cond']) * 0.3 +
#     df_model.drop(columns=['Age', 'Overall_Cond']).sum(axis=1) * (0.4 / (len(df_model.columns) - 2))
# )

# # 7. í‘œì¤€í™”
# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(df_model)

# # 8. Lasso íšŒê·€ë¡œ ê°€ì¤‘ì¹˜ ì‚°ì¶œ
# lasso = LassoCV(cv=5, max_iter=10000)
# lasso.fit(X_scaled, initial_score)

# # 9. ìµœì¢… ìœ ì§€ë³´ìˆ˜ ì ìˆ˜ ê³„ì‚°
# final_weights = pd.Series(lasso.coef_, index=df_model.columns)
# df['MaintenanceNeedScore'] = X_scaled @ lasso.coef_ + lasso.intercept_

# # 10. ì ìˆ˜ ìƒìœ„ í™•ì¸
# df[['Latitude', 'Longitude', 'MaintenanceNeedScore']].sort_values(by='MaintenanceNeedScore', ascending=False).head()


# # df.columns












# ë¼ì˜íšŒê·€ë¥¼ í†µí•œ condition ì ìˆ˜ ì‚°ì¶œ
import pandas as pd
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
import folium

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ê²°ì¸¡ì¹˜ ì œê±°
df = pd.read_csv("./data/house/houseprice-with-lonlat.csv")
df = df.dropna(subset=['Latitude', 'Longitude'])

# 2. ì‚¬ìš©í•  ë³€ìˆ˜ë“¤
cols = ['BsmtCond', 'ExterCond', 'GarageCond', 'YearRemodAdd']

# 3. ë¬¸ìì—´ ì ìˆ˜ ë§¤í•‘
qual_mapping = {
    'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5,
    'Poor': 1, 'Fair': 2, 'Typical': 3, 'Good': 4, 'Excellent': 5,
    'No_Basement': 0, 'No_Garage': 0,
    'Average': 3, 'Below_Average': 2, 'Above_Average': 4,
    'Very_Good': 5, 'Very_Poor': 1
}

# 4. ë¬¸ìì—´ ì ìˆ˜ ë§¤í•‘ì„ dfì— ì§ì ‘ ì ìš©
for col in ['BsmtCond', 'ExterCond', 'GarageCond']:
    if df[col].dtype == object:
        df[col] = df[col].map(qual_mapping)

# 5. ë¦¬ëª¨ë¸ë§ ì—°ë„ ì ìˆ˜í™”
def remod_to_score(year):
    if year < 1960: return 6
    elif year < 1970: return 5
    elif year < 1980: return 4
    elif year < 1990: return 3
    elif year < 2000: return 2
    else: return 1

df['RemodScore'] = df['YearRemodAdd'].apply(remod_to_score)

# 6. ìƒíƒœ ì ìˆ˜ ë’¤ì§‘ê¸° (ì¢‹ìŒ=1 â†’ ë‚˜ì¨=5)
for col in ['BsmtCond', 'ExterCond', 'GarageCond']:
    df[col] = 5 - df[col]

# 7. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
df[['BsmtCond', 'ExterCond', 'GarageCond', 'RemodScore']] = df[[
    'BsmtCond', 'ExterCond', 'GarageCond', 'RemodScore']].fillna(0)

# 8. ì´ˆê¸° ìœ ì§€ë³´ìˆ˜ í•„ìš” ì ìˆ˜ ê³„ì‚°
df['MaintenanceNeedScore'] = (
    df['RemodScore'] * 0.2 +
    df['GarageCond'] * 0.2 +
    df['ExterCond'] * 0.3 +
    df['BsmtCond'] * 0.3
)

# 9. ìƒìœ„ 200ê°œ ì¶”ì¶œ
top200 = df.sort_values(by='MaintenanceNeedScore', ascending=False).head(200)
top200.to_csv('./data/house/top200.csv', index=True)
top25 = df[df['MaintenanceNeedScore'] >= df['MaintenanceNeedScore'].quantile(0.75)][
    ['Latitude', 'Longitude', 'MaintenanceNeedScore']
].sort_values(by='MaintenanceNeedScore', ascending=False)
top10 = df[df['MaintenanceNeedScore'] >= df['MaintenanceNeedScore'].quantile(0.95)][
    ['Latitude', 'Longitude', 'MaintenanceNeedScore']
].sort_values(by='MaintenanceNeedScore', ascending=False)
top10
top10.to_csv('./data/house/top10.csv', index=True)
top25
center_lat = top10['Latitude'].mean()
center_lon = top10['Longitude'].mean()
m = folium.Map(location=[center_lat, center_lon], zoom_start=13)

for _, row in top10.iterrows():
    folium.CircleMarker(
        location=[row['Latitude'], row['Longitude']],
        radius=2,
        fill=True,
        color='red',
        fill_opacity=0.7,
        popup=f"Score: {row['MaintenanceNeedScore']:.2f}"
    ).add_to(m)

# ì €ì¥
m
# HTMLë¡œ ì €ì¥
m.save("./data/house/top10.html")

# step3. ê³ ê°€/ì €ê°€ ì£¼íƒ íšŒê·€ ê³„ìˆ˜ ë¹„êµ
import pandas as pd
import numpy as np
from sklearn.linear_model import ElasticNet
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold, GridSearchCV

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./data/house/houseprice-with-lonlat.csv')

# 2. ìƒìœ„ 25%, í•˜ìœ„ 25% ë¶„í• 
q_high = df['SalePrice'].quantile(0.75)
q_low = df['SalePrice'].quantile(0.25)
df_high = df[df['SalePrice'] >= q_high].copy()
df_low = df[df['SalePrice'] <= q_low].copy()

# 3. ë³€ìˆ˜ ì •ì˜
cond_qual_vars = [
    'KitchenQual', 'FireplaceQu', 'BsmtCond', 'ExterCond', 'GarageCond',
    'OverallCond', 'BsmtQual', 'ExterQual', 'GarageQual', 'HeatingQC'
]

# 4. í’ˆì§ˆ ë§¤í•‘
qual_mapping = {
    'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5,
    'Poor': 1, 'Fair': 2, 'Typical': 3, 'Good': 4, 'Excellent': 5,
    'No_Basement': 0, 'No_Garage': 0,
    'Average': 3, 'Below_Average': 2, 'Above_Average': 4,
    'Very_Good': 5, 'Very_Poor': 1
}

# 1. 'OverallCond'ëŠ” ë§¤í•‘í•˜ì§€ ë§ê³  ì œì™¸
vars_to_map = [v for v in cond_qual_vars if v != 'OverallCond']

# 2. ë§¤í•‘ ì ìš©
for var in vars_to_map:
    df_high[var] = df_high[var].map(qual_mapping)
    df_low[var] = df_low[var].map(qual_mapping)

# 3. ê²°ì¸¡ì¹˜ í‰ê·  ëŒ€ì²´
df_high[vars_to_map] = df_high[vars_to_map].fillna(df_high[vars_to_map].mean())
df_low[vars_to_map] = df_low[vars_to_map].fillna(df_low[vars_to_map].mean())

# 4. ì „ì²´ ë³€ìˆ˜ ëª©ë¡ (ë§¤í•‘í•œ ê²ƒ + ê·¸ëŒ€ë¡œ ë‘” OverallCond)
final_vars = vars_to_map + ['OverallCond']

# 5. í´ë¦° ë°ì´í„° ìƒì„±
df_high_clean = df_high[['SalePrice'] + final_vars].dropna()
df_low_clean = df_low[['SalePrice'] + final_vars].dropna()
# 7. ìŠ¤ì¼€ì¼ë§
scaler_high = StandardScaler()
X_high_scaled = scaler_high.fit_transform(df_high[cond_qual_vars])
y_high = df_high['SalePrice']

scaler_low = StandardScaler()
X_low_scaled = scaler_low.fit_transform(df_low[cond_qual_vars])
y_low = df_low['SalePrice']

# 8. GridSearch íŒŒë¼ë¯¸í„° ì •ì˜
param_grid = {
    'alpha': np.arange(0.01, 0.3, 0.01),
    'l1_ratio': np.linspace(0, 1, 20)
}

cv = KFold(n_splits=5, shuffle=True, random_state=0)

# 9. ê³ ê°€ ëª¨ë¸ í•™ìŠµ
elastic_high = GridSearchCV(
    estimator=ElasticNet(max_iter=1000),
    param_grid=param_grid,
    cv=cv,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
elastic_high.fit(X_high_scaled, y_high)

# 10. ì €ê°€ ëª¨ë¸ í•™ìŠµ
elastic_low = GridSearchCV(
    estimator=ElasticNet(max_iter=1000),
    param_grid=param_grid,
    cv=cv,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
elastic_low.fit(X_low_scaled, y_low)

# 11. ê²°ê³¼ ì¶œë ¥
print("ğŸ“ˆ ê³ ê°€ ì£¼íƒ Best Params:", elastic_high.best_params_)
print("ğŸ“‰ ì €ê°€ ì£¼íƒ Best Params:", elastic_low.best_params_)

print("\nê³ ê°€ ì£¼íƒ Feature Coefficients:")
print(pd.Series(elastic_high.best_estimator_.coef_, index=cond_qual_vars).round(2))

print("\nì €ê°€ ì£¼íƒ Feature Coefficients:")
print(pd.Series(elastic_low.best_estimator_.coef_, index=cond_qual_vars).round(2))


# ìœ„ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
# ê³ ê°€/ì €ê°€ íšŒê·€ ê³„ìˆ˜ ì¶”ì¶œ
coef_high = pd.Series(elastic_high.best_estimator_.coef_, index=cond_qual_vars).round(2)
coef_low = pd.Series(elastic_low.best_estimator_.coef_, index=cond_qual_vars).round(2)

# í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ ë³‘í•©
coef_df = pd.DataFrame({
    'ê³ ê°€ ê³„ìˆ˜': coef_high,
    'ì €ê°€ ê³„ìˆ˜': coef_low
})

# ì¶œë ¥
coef_df